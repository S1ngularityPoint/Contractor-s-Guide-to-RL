{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Train the various algorithms and show your results. \n",
    "\n",
    "You must plot the reward obtained by your agent per step and the total regret accumulated so far.\n",
    "\n",
    "This one is an open ended assignment, so feel free to play around. Extra credit for more beautiful plots (you can check out Seaborn). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# import seaborn as sns\n",
    "\n",
    "from bandits import Bandit\n",
    "from agents import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent(agent, num_steps):\n",
    "    rewards_per_step = []\n",
    "    tot_regret=[]\n",
    "    for i in range(num_steps):\n",
    "        current_reward = agent.act()\n",
    "        rewards_per_step.append(agent.rewards/(i+1))\n",
    "        tot_regret.append(agent.bandit.regret)\n",
    "    return rewards_per_step,tot_regret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rewards(rewards_per_step,tot_regret,agent_name):\n",
    "    ax1.plot(rewards_per_step, label=agent_name)\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.set_xlabel('Time Steps')\n",
    "    ax1.set_ylabel('Mean Reward')\n",
    "    ax1.legend()\n",
    "    ax2.plot(tot_regret, label=agent_name)\n",
    "    ax2.set_yscale('log')\n",
    "    ax2.set_xlabel('Time Steps')\n",
    "    ax2.set_ylabel('Total Regret')\n",
    "    ax2.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for bandit_type in Bandit.BANDIT_TYPES:\n",
    "    bandit=Bandit(n=10,type=bandit_type)\n",
    "    agents=[\n",
    "        GreedyAgent(bandit,0.0),\n",
    "        epsGreedyAgent(bandit,0.1),\n",
    "        UCBAAgent(bandit,2),\n",
    "        GradientBanditAgent(bandit,0.1),\n",
    "        ThompsonSamplerAgent(bandit)\n",
    "    ]\n",
    "    for agent in agents:\n",
    "        rewards_per_step,tot_regret=train_agent(agent,num_steps)\n",
    "        plot_rewards(rewards_per_step,tot_regret, f\"{type(agent).__name__} ({bandit_type})\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
